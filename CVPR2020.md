# CVPR2020最新信息及论文下载贴（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）


官网链接：http://cvpr2020.thecvf.com/<br>
时间：Seattle, Washington，2020年6月14日-6月19日<br>
论文接收公布时间：2020年2月24日<br>

相关问题：
* [如何评价2020年计算机视觉顶会CVPR投稿量破万的现象?](https://www.zhihu.com/question/356099725/)<br>
* [如何评价 CVPR 2020的论文接收结果？有哪些亮点论文？](https://www.zhihu.com/question/372070853)<br><br>

# 总目录
[1. CVPR2020接收论文（持续更新）](#100)<br>
[2. CVPR2020 Oral（持续更新）](#101)<br>
[3. CVPR2020 论文解读](#102)<br>
[4. To do list](#103)<br>
[5. Related works](#104)<br>


<br><br>

<a name="100"/>

# 1.CVPR2020接收论文（持续更新）<br>




<br>

### 目录<br>
[1. 目标检测](#1)<br>
[2. 图像分割](#2)<br>
[3. 人脸识别](#3)<br>
[4. 目标跟踪](#4)<br>
[5. 三维点云/三维重建/三维检测/三维分割/深度估计](#5)<br>
[6. 图像处理](#6)<br>
[7. 图像分类](#7)<br>
[8. 姿态估计/动作识别](#8)<br>
[9. 视频分析](#9)<br>
[10. OCR](#10)<br>
[11. GAN](#11)<br>
[12. 小样本/零样本](#12)<br>
[13. 弱监督/无监督/自监督](#13)<br>
[14. 行人跟踪/行人检测/ReID](#14)<br>
[15. 神经网络/模型加速/模型压缩](#15)<br>
[16. 超分辨率](#16)<br>
[17. 视觉常识/数据集/其他](#17)<br>


<br><br>

<a name="1"/>

### 目标检测

1. Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection<br>
论文地址：https://arxiv.org/abs/1912.02424   <br>
代码：https://github.com/sfzhang15/ATSS<br><br>

2. Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector<br>
论文地址：https://arxiv.org/abs/1908.01998<br><br>

3. AugFPN: Improving Multi-scale Feature Learning for Object Detection<br>
论文地址：https://arxiv.org/abs/1912.05384<br><br>

4. Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection<br>
论文地址：https://arxiv.org/abs/2003.11818<br>
代码：https://github.com/ggjy/HitDet.pytorch<br><br>

5. Multi-task Collaborative Network for Joint Referring Expression Comprehension and Segmentation<br>
论文地址：https://arxiv.org/abs/2003.08813<br><br>

6. CentripetalNet: Pursuing High-quality Keypoint Pairs for Object Detection<br>
论文地址：https://arxiv.org/abs/2003.09119<br>
代码：https://github.com/KiveeDong/CentripetalNet<br><br>

<br><br>

<a name="2"/>

### 图像分割

1. Semi-Supervised Semantic Image Segmentation with Self-correcting Networks<br>
论文地址：https://arxiv.org/abs/1811.07073<br><br>

2. Deep Snake for Real-Time Instance Segmentation<br>
论文地址：https://arxiv.org/abs/2001.01629<br><br>

3. CenterMask : Real-Time Anchor-Free Instance Segmentation<br>
论文地址：https://arxiv.org/abs/1911.06667<br>
代码：https://github.com/youngwanLEE/CenterMask<br><br>

4. SketchGCN: Semantic Sketch Segmentation with Graph Convolutional Networks<br>
论文地址：https://arxiv.org/abs/2003.00678<br><br>

5. PolarMask: Single Shot Instance Segmentation with Polar Representation<br>
论文地址：https://arxiv.org/abs/1909.13226<br>
代码：https://github.com/xieenze/PolarMask<br><br>


6. xMUDA: Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation<br>
论文地址：https://arxiv.org/abs/1911.12676<br><br>

7. BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation<br>
论文地址：https://arxiv.org/abs/2001.00309<br><br>

8. Enhancing Generic Segmentation with Learned Region Representations<br>
论文地址：https://arxiv.org/abs/1911.08564<br><br>

<br><br>

<a name="3"/>

### 人脸识别

1. Towards Universal Representation Learning for Deep Face Recognition<br>
论文地址：https://arxiv.org/abs/2002.11841<br><br>

2. Suppressing Uncertainties for Large-Scale Facial Expression Recognition   <br>    
论文地址：https://arxiv.org/abs/2002.10392<br>
代码：https://github.com/kaiwang960112/Self-Cure-Network<br><br>

3. Face X-ray for More General Face Forgery Detection<br>
论文地址：https://arxiv.org/pdf/1912.13458.pdf<br><br>

4. Pose Agnostic Cross-spectral Hallucination via Disentangling Independent Factors<br>
论文地址：https://arxiv.org/abs/1909.04365<br><br>

5. Deep Spatial Gradient and Temporal Depth Learning for Face Anti-spoofing<br>
论文地址：https://arxiv.org/abs/2003.08061<br>
代码：https://github.com/clks-wzz/FAS-SGTD<br><br>

6. Learning Meta Face Recognition in Unseen Domains<br>
论文地址：https://arxiv.org/abs/2003.07733<br>
代码：https://github.com/cleardusk/MFR<br><br>


<br><br>

<a name="4"/>

### 目标跟踪

1. ROAM: Recurrently Optimizing Tracking Model<br>
论文地址：https://arxiv.org/abs/1907.12006 <br><br>

<br><br>

<a name="5"/>

### 三维点云/三维重建/三维检测/三维分割/深度估计

* 三维点云&重建

1. PF-Net: Point Fractal Network for 3D Point Cloud Completion<br>
论文地址：https://arxiv.org/abs/2003.00410<br><br>

2. PointAugment: an Auto-Augmentation Framework for Point Cloud Classification<br>
论文地址：https://arxiv.org/abs/2002.10876<br>
代码：https://github.com/liruihui/PointAugment/<br><br>

3. Learning multiview 3D point cloud registration<br>
论文地址：https://arxiv.org/abs/2001.05119<br><br>

4. C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds<br>
论文地址：https://arxiv.org/abs/1912.07009<br><br>

5. RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds<br>
论文地址：https://arxiv.org/abs/1911.11236 <br><br>


6. Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image<br>
论文地址：https://arxiv.org/abs/2002.12212<br><br>

7. Implicit Functions in Feature Space for 3D Shape Reconstruction and Completion<br>
论文地址：https://arxiv.org/abs/2003.01456<br><br>

8. In Perfect Shape: Certifiably Optimal 3D Shape Reconstruction from 2D Landmarks<br>
论文地址：https://arxiv.org/pdf/1911.11924.pdf<br><br>

9. Attentive Context Normalization for Robust Permutation-Equivariant Learning<br>
论文地址：https://arxiv.org/abs/1907.02545	Weiwei Sun, Wei Jiang, Eduard Trulls, Andrea Tagliasacchi, Kwang Moo Yi<br><br>

10. PQ-NET: A Generative Part Seq2Seq Network for 3D Shapes	<br>
论文地址：https://arxiv.org/abs/1911.10949	<br><br>

11. SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans<br>
论文地址：https://arxiv.org/abs/1912.00036<br><br>

12. Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching<br>
论文地址：https://arxiv.org/abs/1912.06378<br>
代码：https://github.com/alibaba/cascade-stereo<br><br>

13. Unsupervised Learning of Intrinsic Structural Representation Points<br>
论文地址：https://arxiv.org/abs/2003.01661<br>
代码：https://github.com/NolenChen/3DStructurePoints<br><br>

* 三维重建
1. Leveraging 2D Data to Learn Textured 3D Mesh Generation <br>	
论文地址：https://arxiv.org/abs/2004.04180<br><br>

2. ARCH: Animatable Reconstruction of Clothed Humans<br>	
论文地址：https://arxiv.org/abs/2004.04572<br><br>

3. Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions<br>	
论文地址：https://arxiv.org/abs/2004.03967<br><br>
<br><br>

<a name="6"/>

### 图像处理

1. Learning to Shade Hand-drawn Sketches<br>
论文地址：https://arxiv.org/abs/2002.11812<br><br>

2. Single Image Reflection Removal through Cascaded Refinement<br>
论文地址：https://arxiv.org/abs/1911.06634<br><br>

3. Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data<br>
论文地址：https://arxiv.org/abs/2002.11297<br><br>

4. Deep Image Harmonization via Domain Verification<br>
论文地址：https://arxiv.org/abs/1911.13239<br>
代码：https://github.com/bcmi/Image_Harmonization_Datasets<br><br>

5. RoutedFusion: Learning Real-time Depth Map Fusion<br>
论文地址：https://arxiv.org/pdf/2001.04388.pdf <br><br>

6. Neural Contours: Learning to Draw Lines from 3D Shapes<br>
论文地址：https://arxiv.org/abs/2003.10333<br><br>

7. Towards Photo-Realistic Virtual Try-On by Adaptively Generating鈫Preserving Image Content<br>
论文地址：https://arxiv.org/abs/2003.05863<br><br>

8. Reinforced Feature Points: Optimizing Feature Detection and Description for a High-Level Task（图像处理-图像特征匹配）<br>
论文地址：https://arxiv.org/abs/1912.00623<br><br>

9. Correspondence Networks with Adaptive Neighbourhood Consensus（图像处理-图像特征匹配）<br>
论文地址：https://arxiv.org/abs/2003.12059<br><br>

10. Normalized and Geometry-Aware Self-Attention Network for Image Captioning（图像处理-图像字幕）<br>
论文地址：https://arxiv.org/abs/2003.08897<br><br>

<br>

<a name="7"/>

### 图像分类

1. Self-training with Noisy Student improves ImageNet classification<br>
论文地址：https://arxiv.org/abs/1911.04252<br><br>

2. Image Matching across Wide Baselines: From Paper to Practice<br>
论文地址：https://arxiv.org/abs/2003.01587<br><br>

3. Towards Robust Image Classification Using Sequential Attention Models<br>
论文地址：https://arxiv.org/abs/1912.02184<br><br>

4. Learning in the Frequency Domain	<br>
论文地址：https://arxiv.org/abs/2002.12416<br><br>

5. Learning from Web Data with Memory Module	<br>
论文地址：https://arxiv.org/abs/1906.12028<br><br>

6. Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks	<br>
论文地址：https://arxiv.org/abs/1912.09393 <br><br>

<br><br>

<a name="8"/>

### 姿态估计/动作识别

1. VIBE: Video Inference for Human Body Pose and Shape Estimation<br>
论文地址：https://arxiv.org/abs/1912.05656  <br> 
代码：https://github.com/mkocabas/VIBE<br><br>

2. Distribution-Aware Coordinate Representation for Human Pose Estimation<br>
论文地址：https://arxiv.org/abs/1910.06278   <br>
代码：https://github.com/ilovepose/DarkPose<br><br>

3. 4D Association Graph for Realtime Multi-person Motion Capture Using Multiple Video Cameras<br>
论文地址：https://arxiv.org/abs/2002.12625<br><br>

4. Optimal least-squares solution to the hand-eye calibration problem<br>
论文地址：https://arxiv.org/abs/2002.10838<br><br>

5. D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry<br>
论文地址：https://arxiv.org/abs/2003.01060<br><br>

6. Multi-Modal Domain Adaptation for Fine-Grained Action Recognition<br>
论文地址：https://arxiv.org/abs/2001.09691<br><br>

7. Distribution Aware Coordinate Representation for Human Pose Estimation<br>
论文地址：https://arxiv.org/abs/1910.06278<br><br>

8. The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation<br>
论文地址：https://arxiv.org/abs/1911.07524<br><br>

9. PVN3D: A Deep Point-wise 3D Keypoints Voting Network for 6DoF Pose Estimation<br>
论文地址：https://arxiv.org/abs/1911.04231<br><br>

10. Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation<br>
论文地址：https://arxiv.org/abs/2003.02824<br><br>

11. G2L-Net: Global to Local Network for Real-time 6D Pose Estimation with Embedding Vector Features<br>
论文地址：https://arxiv.org/abs/2003.11089<br><br>

12. Deep Image Spatial Transformation for Person Image Generation<br>
论文地址：https://arxiv.org/abs/2003.00696<br>
代码：https://github.com/RenYurui/ Global-Flow-Local-Attention<br><br>


<br><br>

<a name="9"/>

### 视频分析

1. Rethinking Zero-shot Video Classification: End-to-end Training for Realistic Applications<br>
论文地址：https://arxiv.org/abs/2003.01455   <br>
代码：https://github.com/bbrattoli/ZeroShotVideoClassification<br><br>

2. Say As You Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs<br>
论文地址：https://arxiv.org/abs/2003.00387<br><br>

3. Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning<br>
论文地址：https://arxiv.org/abs/2003.00392<br><br>

4. Object Relational Graph with Teacher-Recommended Learning for Video Captioning<br>
论文地址：https://arxiv.org/abs/2002.11566<br><br>

5. Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution<br>
论文地址：https://arxiv.org/abs/2002.11616<br><br>

6. Blurry Video Frame Interpolation<br>
论文地址：https://arxiv.org/abs/2002.12259<br><br>

7. Hierarchical Conditional Relation Networks for Video Question Answering<br>
论文地址：https://arxiv.org/abs/2002.10698   <br><br>

8. Action Modifiers:Learning from Adverbs in Instructional Video<br>
论文地址：https://arxiv.org/abs/1912.06617     <br><br>

9. Visual Grounding in Video for Unsupervised Word Translation<br>
论文地址：https://arxiv.org/abs/2003.05078<br>
代码：https://github.com/gsig/visual-grounding<br><br>

10. MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask（视频分析-光流估计）<br>
论文地址：https://arxiv.org/abs/2003.10955<br>
代码：https://github.com/microsoft/MaskFlownet<br><br>

11. Use the Force, Luke! Learning to Predict Physical Forces by Simulating Effects（视频预测）<br>
论文地址：https://arxiv.org/abs/2003.12045<br>
代码：https://ehsanik.github.io/forcecvpr2020<br><br>


<br><br>

<a name="10"/>

### OCR

1. ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network<br>
论文地址：https://arxiv.org/abs/2002.10200<br>
代码：https://github.com/Yuliang-Liu/bezier_curve_text_spotting,https://github.com/aim-uofa/adet<br><br>

2.Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA<br>
论文地址：https://arxiv.org/abs/1911.06258<br><br>

<br><br>

<a name="11"/>

### GAN

1. Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models<br>
论文地址：https://arxiv.org/abs/1911.12287<br>
代码：https://github.com/giannisdaras/ylg<br><br>

2. MSG-GAN: Multi-Scale Gradient GAN for Stable Image Synthesis<br>
论文地址：https://arxiv.org/abs/1903.06048<br><br>

3. Robust Design of Deep Neural Networks against Adversarial Attacks based on Lyapunov Theory<br>
论文地址：https://arxiv.org/abs/1911.04636<br><br>

4.PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer<br>
论文地址：https://arxiv.org/abs/1909.06956<br><br>


<br><br>

<a name="12"/>

### 小样本/零样本

1. Improved Few-Shot Visual Classification<br>
论文地址：https://arxiv.org/pdf/1912.03432.pdf <br><br>

2. Meta-Transfer Learning for Zero-Shot Super-Resolution<br>
论文地址：https://arxiv.org/abs/2002.12213<br><br>

3. Instance Credibility Inference for Few-Shot Learning<br>
论文地址：https://arxiv.org/abs/2003.11853<br>
代码：https://github.com/Yikai-Wang/ICI-FSL<br><br>

<br><br>

<a name="13"/>

### 弱监督/无监督/自监督

1. Rethinking the Route Towards Weakly Supervised Object Localization<br>
论文地址：https://arxiv.org/abs/2002.11359<br><br>

2. NestedVAE: Isolating Common Factors via Weak Supervision<br>
论文地址：https://arxiv.org/abs/2002.11576 <br><br>

3. Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation<br>
论文地址：https://arxiv.org/abs/1911.07450<br><br>

4. Disentangling Physical Dynamics from Unknown Factors for Unsupervised Video Prediction<br>
论文地址：https://arxiv.org/abs/2003.01460<br><br>

5. ClusterFit: Improving Generalization of Visual Representations<br>
论文地址：https://arxiv.org/abs/1912.03330<br><br>

6. Auto-Encoding Twin-Bottleneck Hashing<br>
论文地址：https://arxiv.org/abs/2002.11930<br><br>

7. Learning Representations by Predicting Bags of Visual Words<br>
论文地址：https://arxiv.org/abs/2002.12247<br><br>

8. A Characteristic Function Approach to Deep Implicit Generative Modeling<br>
论文地址：https://arxiv.org/abs/1909.07425<br><br>

9. Unsupervised Learning of Intrinsic Structural Representation Points<br>
论文地址：https://arxiv.org/abs/2003.01661<br>
代码：https://github.com/NolenChen/3DStructurePoints<br><br>


<br><br>

<a name="14"/>

### 行人跟踪/行人检测/ReID
1. Cross-modality Person re-identification with Shared-Specific Feature Transfer	<br>
论文地址：https://arxiv.org/abs/2002.12489 <br><br>

2.Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction	<br>
论文地址：https://arxiv.org/abs/2002.11927<br><br>

3.The Garden of Forking Paths: Towards Multi-Future Trajectory Prediction	<br>
论文地址：https://arxiv.org/abs/1912.06445<br><br>

<br><br>

<a name="15"/>

### 神经网络/模型压缩/模型加速

1. GhostNet: More Features from Cheap Operations<br>
论文地址：https://arxiv.org/abs/1911.11907<br>
代码：https://github.com/iamhankai/ghostnet<br><br>

2. Watch your Up-Convolution: CNN Based Generative Deep Neural Networks are Failing to Reproduce Spectral <br>
论文地址：https://arxiv.org/abs/2003.01826<br><br>

3. GPU-Accelerated Mobile Multi-view Style Transfer<br>
论文地址：https://arxiv.org/abs/2003.00706<br><br>

4. Bundle Adjustment on a Graph Processor		<br>
论文地址：https://arxiv.org/abs/2003.03134		<br>
代码：https://github.com/joeaortiz/gbp<br><br>

5. Watch your Up-Convolution: CNN Based Generative Deep Neural Networks are Failing to Reproduce Spectral 	<br>
论文地址：https://arxiv.org/abs/2003.01826	<br><br>

6. Holistically-Attracted Wireframe Parsing	<br>
论文地址：https://arxiv.org/abs/2003.01663	<br><br>

7. AdderNet: Do We Really Need Multiplications in Deep Learning? 	<br>
论文地址：https://arxiv.org/abs/1912.13200 	<br><br>

8. CARS: Contunuous Evolution for Efficient Neural Architecture Search	<br>
论文地址：https://arxiv.org/abs/1909.04977	 	<br>
代码：https://github.com/huawei-noah/CARS<br><br>

9. Π-nets: Deep Polynomial Neural Networksv<br>
论文地址：https://arxiv.org/abs/2003.03828<br><br>

10. Explaining Knowledge Distillation by Quantifying the Knowledge<br>
论文地址：https://arxiv.org/abs/2003.03622<br><br>

<br><br>

<a name="16"/>

### 超分辨率

1. Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution	<br>
论文地址：https://arxiv.org/abs/2002.11616<br><br>

2.Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution <br>
论文地址：https://arxiv.org/abs/2003.07018<br>
代码：https://github.com/guoyongcs/DRN<br><br>

<br><br>

<a name="17"/>

### 视觉常识/其他

1. Visual Commonsense R-CNN<br>
论文地址：https://arxiv.org/abs/2002.12204<br>
代码：https://github.com/Wangt-CN/VC-R-CNN<br><br>

2. Scalable Uncertainty for Computer Vision with Functional Variational Inference	<br>
论文地址：https://arxiv.org/abs/2003.03396<br><br>

3. Deep Representation Learning on Long-tailed Data: A Learnable Embedding Augmentation Perspective	<br>
论文地址：https://arxiv.org/abs/2002.10826<br><br>

4. Representations, Metrics and Statistics For Shape Analysis of Elastic Graphs	<br>
论文地址：https://arxiv.org/abs/2003.00287	<br><br>
				
5. Filter Grafting for Deep Neural Networks	<br>
论文地址：https://arxiv.org/abs/2001.05868<br>
代码：https://github.com/fxmeng/filter-grafting.git<br><br>

6. 12-in-1: Multi-Task Vision and Language Representation Learning<br>
论文地址：https://arxiv.org/abs/1912.02315 	<br><br>
				
7. Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-training	<br>
论文地址：https://arxiv.org/abs/2002.10638		<br>
代码：https://github.com/weituo12321/PREVALENT<br><br>

8. Unbiased Scene Graph Generation from Biased Training	<br>
论文地址：https://arxiv.org/abs/2002.11949 <br><br>

9.Towards Visually Explaining Variational Autoencoders<br>
论文地址：https://arxiv.org/abs/1911.07389<br><br>

10. BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition<br>
论文地址：http://www.weixiushen.com/publication/cvpr20_BBN.pdf<br>
代码：https://github.com/Megvii-Nanjing/BBN<br><br>

11. High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks<br>
论文地址：https://arxiv.org/abs/1905.13545<br><br>

12. SAM: The Sensitivity of Attribution Methods to Hyperparameters<br>
论文地址：http://s.anhnguyen.me/sam\_cvpr2020.pdf<br>
代码：https://github.com/anguyen8/sam<br><br>

13. Π− nets: Deep Polynomial Neural Networks<br>
论文地址：https://arxiv.org/abs/2003.03828<br><br>

14. Towards Backward-Compatible Representation Learning<br>
论文地址：https://arxiv.org/abs/2003.11942<br><br>

15. On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location<br>
论文地址：https://arxiv.org/abs/2003.07064<br><br>

16. KeypointNet: A Large-scale 3D Keypoint Dataset Aggregated from Numerous Human Annotations（数据集）<br>
论文地址：https://arxiv.org/abs/2002.12687<br><br>


<br><br>

<a name="101"/>

# 2.CVPR2020 Oral（持续更新）<br>
[1. PolarMask: Single Shot Instance Segmentation with Polar Representation](https://arxiv.org/abs/1909.13226)<br>
代码：https://github.com/xieenze/PolarMask <br><br>

[2. Unbiased Scene Graph Generation from Biased Training](https://arxiv.org/abs/2002.11949) <br>
代码：https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch <br><br>

[3. Learning to Shade Hand-drawn Sketches](https://arxiv.org/abs/2002.11812) <br>
代码：https://github.com/qyzdao/ShadeSketch <br><br>

[4. SAM: The Sensitivity of Attribution Methods to Hyperparameters](http://s.anhnguyen.me/sam_cvpr2020.pdf)<br>
代码：https://github.com/anguyen8/sam<br><br>

[5. High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks](https://arxiv.org/abs/1905.13545)<br><br>

[6. Reinforced Feature Points: Optimizing Feature Detection and Description for a High-Level Task](https://arxiv.org/abs/1912.00623) <br><br>

[7. RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds](https://arxiv.org/abs/1911.11236)<br><br>

[8. AdderNet: Do We Really Need Multiplications in Deep Learning? ](https://arxiv.org/abs/1912.13200 )<br><br>

[9. Multi-Modal Domain Adaptation for Fine-Grained Action Recognition](https://arxiv.org/abs/2001.09691 )<br><br>

[10. Multi-task Collaborative Network for Joint Referring Expression Comprehension and Segmentation](https://arxiv.org/abs/2003.08813)<br><br>

[11. Deep Spatial Gradient and Temporal Depth Learning for Face Anti-spoofing](https://arxiv.org/abs/2003.08061)<br>
https://github.com/clks-wzz/FAS-SGTD<br><br>

[12. Learning Meta Face Recognition in Unseen Domains](https://arxiv.org/abs/2003.07733)<br>
https://github.com/cleardusk/MFR<br><br>

[13. Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching](https://arxiv.org/abs/1912.06378)<br>
https://github.com/alibaba/cascade-stereo<br><br>

[14. BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition](http://www.weixiushen.com/publication/cvpr20_BBN.pdf)<br>
https://github.com/Megvii-Nanjing/BBN<br><br>

[15. High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks](https://arxiv.org/abs/1905.13545)<br><br>

[16. SAM: The Sensitivity of Attribution Methods to Hyperparameters](http://s.anhnguyen.me/sam\_cvpr2020.pdf)<br>
https://github.com/anguyen8/sam<br><br>

[17. Towards Backward-Compatible Representation Learning](https://arxiv.org/abs/2003.11942)<br><br>

[18. MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask](https://arxiv.org/abs/2003.10955)<br>
https://github.com/microsoft/MaskFlownet<br><br>

[19. Use the Force, Luke! Learning to Predict Physical Forces by Simulating Effects](https://arxiv.org/abs/2003.12045)<br>
https://ehsanik.github.io/forcecvpr2020<br><br>

[20. StyleRig: Rigging StyleGAN for 3D Control over Portrait Images](https://arxiv.org/abs/2004.00121)<br><br>

[21. Conditional Channel Gated Networks for Task-Aware Continual Learning](https://arxiv.org/abs/2004.00070)

[22. BANet: Bidirectional Aggregation Network with Occlusion Handling for Panoptic Segmentation](https://arxiv.org/abs/2003.14031)<br><br>

[23. TITAN: Future Forecast using Action Priors](https://arxiv.org/abs/2003.13886)<br><br>

[24. Learning Interactions and Relationships between Movie Characters](https://arxiv.org/abs/2003.13158)<br><br>

[25. GPS-Net: Graph Property Sensing Network for Scene Graph Generation](https://arxiv.org/abs/2003.12962)<br>
https://github.com/taksau/GPS-Net<br><br>

[26. A Physics-based Noise Formation Model for Extreme Low-light Raw Denoising](https://arxiv.org/abs/2003.12751)<br>
https://github.com/Vandermode/NoiseModel<br><br>

[27. Controllable Person Image Synthesis with Attribute-Decomposed GAN](https://arxiv.org/abs/2003.12267)<br>
https://menyifang.github.io/projects/ADGAN/ADGAN.html<br><br>

[28. Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label Insufficient Situations](https://arxiv.org/abs/2003.12237)<br><br>

[29. Learning to Optimize Non-Rigid Tracking](https://arxiv.org/abs/2003.12230)<br><br>

[30. Self-Supervised Scene De-occlusion](https://arxiv.org/abs/2004.02788)<br>
https://xiaohangzhan.github.io/projects/deocclusion/<br><br>

[31. Robust 3D Self-portraits in Seconds](https://arxiv.org/abs/2004.02460)<br><br>

[32. Steering Self-Supervised Feature Learning Beyond Local Pixel Statistics](https://arxiv.org/abs/2004.02331)<br><br>

[33. Light Field Spatial Super-resolution via Deep Combinatorial Geometry Embedding and Structural Consistency Regularization](https://arxiv.org/abs/2004.02215)<br><br>

[34. Google Landmarks Dataset v2 -- A Large-Scale Benchmark for Instance-Level Recognition and Retrieval](https://arxiv.org/abs/2004.01804)<br><br>

[35. Deep White-Balance Editing](https://arxiv.org/abs/2004.01354)<br><br>

[36. Tracking by Instance Detection: A Meta-Learning Approach](https://arxiv.org/abs/2004.00830)<br><br>



<br><br>

<a name="102"/>

# 3.CVPR2020 论文解读<br><br>


### [15.无监督的视觉常识特征学习——因果关系上的一点探索](https://zhuanlan.zhihu.com/p/111306353)<br>
如今越来越多的研究者开始关注如何将统计中的因果应用于deep learning，来增加其鲁棒性、可解释性等等。但是大部分工作都没有深入因果理论中，更多的是借用了其中一些概念（比如counterfactual反事实），这篇paper旨在能在此基础上再向前走一点。<br>
论文链接：https://arxiv.org/abs/2002.12204<br>
论文代码：https://github.com/Wangt-CN/VC-R-CNN<br><br>

### [14.CVPR2020 | 最新最完善的场景图生成 (SGG)开源框架，集成目前最全metrics，已开源](https://mp.weixin.qq.com/s/Nj6GjpRG8qG1ihhcoY9SwQ)<br>
选择2019年热门框架facebookresearch/maskrcnn-benchmark作为基础，在其基础上搭建了Scene-Graph-Benchmark.pytorch。该代码不仅兼容了maskrcnn-benchmark所支持的所有detector模型，且得益于facebookresearch优秀的代码功底，更大大增加了SGG部分的可读性和可操作性。<br>
论文链接：https://arxiv.org/abs/2002.11949<br>
论文代码：https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch<br><br>


### [13.CVPR2020 | 旷视研究院提出基于3D关键点投票网络的单目6DoF位姿估计算法(已开源)](https://mp.weixin.qq.com/s/c8rQYj5lSOtI1iza9e0Dpw)<br>
论文链接：https://arxiv.org/abs/1911.04231<br>
论文代码：https://github.com/ethnhe/PVN3D.git<br>
旷视研究院提出一种基于霍夫投票（Hough voting)的 3D 关键点检测神经网络，称之为 PVN3D，以学习逐点到 3D 关键点的偏移并为 3D 关键点投票。把基于 2D 关键点的方法推进至 3D 关键点，以充分利用刚体的几何约束信息，极大提升了 6DoF 估计的精确性。在 YCB-Video 和 LineMOD 两大公开数据集上进行了评估实验，结果表明该方法以大幅优势取得了当前最佳性能。
<br><br>


### [12.跨模态行人重识别：共享与特异特征变换算法cm-SSFT](https://mp.weixin.qq.com/s/qPc71o2JeMDpDgRxDtp2BA)<br>
论文链接：https://arxiv.org/abs/2002.12489<br>
关注红外线-RGB跨模态行人重识别。试图解决：以往大部分跨模态行人重识别算法一般都只关注shared feature learning，而很少关注Specific feature。因为Specific feature在对面模态中是不存在的。例如在红外线图片中是没有彩色颜色信息的。反之在彩图中也不会有热度信息。而实际上做过ReID的都知道，传统ReID之所以性能很高，很大程度上就是有些“过拟合”到了这些specific信息上。比如衣服颜色一直是传统ReID的一个重要的cue。从这个角度出发，尝试利用specific特征。主要思路是利用近邻信息：给定一红外线query。当搜索彩色target时，可以先找到一些简单的置信度高的彩色样本（这些样本大概率是红外线query的positive样本），把这些彩色样本的颜色特异特征给与红外线query。做了这件事后，红外线query样本可以利用这些彩色信息再去搜索更难的彩色样本。<br><br>

### [11.RandLA-Net:大场景三维点云语义分割新框架（已开源）](https://mp.weixin.qq.com/s/xuLJ8m_ipGVBXVduA7Y0IA)<br>
论文链接：https://arxiv.org/abs/1911.11236<br>
代码：https://github.com/QingyongHu/RandLA-Net<br>
提出了一种基于简单高效的随机降采样和局部特征聚合的网络结构(RandLA-Net)。该方法不仅在诸如Semantic3D和SemanticKITTI等大场景点云分割数据集上取得了非常好的效果，并且具有非常高的效率(e.g. 比基于图的方法SPG快了接近200倍)。<br><br>


### [10.腾讯推出超强少样本目标检测算法，公开千类少样本检测训练集FSOD](https://mp.weixin.qq.com/s/TRRsBGzMir0ttzjTdXwJCw)<br>
论文链接：https://arxiv.org/abs/1908.01998<br>
提出了新的少样本目标检测算法，创新点包括Attention-RPN、多关系检测器以及对比训练策略，另外还构建了包含1000类的少样本检测数据集FSOD，在FSOD上训练得到的论文模型能够直接迁移到新类别的检测中，不需要fine-tune<br><br>

### [9.CARS: 华为提出基于进化算法和权值共享的神经网络结构搜索，CIFAR-10上仅需单卡半天](https://mp.weixin.qq.com/s/GAL-hbERLp6vS2zB_I9jxg)
<br>
论文链接：https://arxiv.org/abs/1909.04977<br>
为了优化进化算法在神经网络结构搜索时候选网络训练过长的问题，参考ENAS和NSGA-III，论文提出连续进化结构搜索方法(continuous evolution architecture search, CARS)，最大化利用学习到的知识，如上一轮进化的结构和参数。首先构造用于参数共享的超网，从超网中产生子网，然后使用None-dominated排序策略来选择不同大小的优秀网络，整体耗时仅需要0.5 GPU day。<br><br>

### [8.化繁为简，弱监督目标定位领域的新SOTA - 伪监督目标定位方法(PSOL)](https://mp.weixin.qq.com/s/6G7BG8DrKZ0Zvi-BUqg78w)<br>

论文链接：https://arxiv.org/abs/2002.11359<br>
论文提出伪监督目标定位方法(PSOL)来解决目前弱监督目标定位方法的问题，该方法将定位与分类分开成两个独立的网络，然后在训练集上使用Deep descriptor transformation(DDT)生成伪GT进行训练，整体效果达到SOTA。 该论文主要有三点贡献：一、弱监督目标定位应该分为类不可知目标定位和目标分类两个独立的部分，提出PSOL算法；二、尽管生成的bbox有偏差，论文仍然认为应该直接优化他们而不需要类标签，最终达到SOTA；三、在不同的数据集上，PSOL算法不需要fine-tuning也能有很好的定位迁移能力<br><br>


### [7.字节跳动：基于解剖学感知的视频3D人体姿态估计](https://mp.weixin.qq.com/s/ut8CmEZPc3NMDdlgXfUzGg)<br>

论文链接：https://arxiv.org/pdf/2002.10322.pdf<br>
在这项工作中，我们提出了一种新的视频中3D人体姿态估计的解决方案。我们不是直接回归3D关节位置，而是从人体骨骼解剖中汲取灵感，将任务分解为骨骼方向预测和骨骼长度预测，从这两个预测中完全可以得到三维关节位置。我们的研究动机是人类骨骼的长度随着时间的推移保持一致。这推动了我们开发有效的技术来利用视频中所有帧的全局信息来进行高精度的骨骼长度预测。此外，对于骨骼方向预测网络，我们提出了一种具有长跳跃连接的全卷积传播结构。本质上，它分层地预测不同骨骼的方向，而不使用任何耗时的存储单元(例如LSTM)。进一步引入了一种新的关节位移损失来连接骨骼长度和骨骼方向预测网络的训练。最后，我们采用一种隐含的注意机制将2D关键点可见性分数作为额外的指导反馈到模型中，这显著地缓解了许多具有挑战性的姿势中的深度歧义。我们的完整模型在Human3.6M和MPI-INF-3dHP数据集上的表现优于之前的最好结果，在这些数据集上的综合评估验证了我们模型的有效性。<br><br>


### [6.微软亚洲研究院：给Deepfake 假脸做 X-Ray，新模型把换脸图打回原形](https://mp.weixin.qq.com/s/DLxqGFm6IRffPa8A0XBc4w)<br>

论文链接：论文地址：https://arxiv.org/pdf/1912.13458.pdf<br>
微软亚洲研究院提出了一个方法，它既不需要了解换脸后的图像数据，也不需要知道换脸算法，就能对图像做『X-Ray』，鉴别出是否换脸，以及指出换脸的边界。
新模型 Face X-Ray 具有两大属性：能泛化到未知换脸算法、能提供可解释的换脸边界。要获得这样的优良属性，诀窍就藏在换脸算法的一般过程中。如下所示，大多数换脸算法可以分为检测、修改以及融合三部分。与之前的研究不同，Face X-Ray 希望检测第三阶段产生的误差。<br><br>

### [5.UDP：人体姿态估计中的无偏数据处理方法](https://mp.weixin.qq.com/s/J1Y0tSIpfTOZ4J-9PPyhag)<br>

论文链接：https://arxiv.org/abs/1911.07524<br>
UDP，解决了现有的SOTA人体姿态估计算法中标准编解码方法存在较大统计误差的问题。同时解决了由于翻转测试而导致的结果不对齐问题。且该算法即用即插，在基本不增加模型复杂度的情况下，有效提升了算法性能。<br><br>

### [4.让合成图像更真实，上交大提出基于域验证的图像和谐化](https://mp.weixin.qq.com/s/JgQ7bgc_bfgWE-PmJMKtOA)<br>

论文链接：https://arxiv.org/abs/1911.13239<br>
在合成图中，前景和背景是在不同的拍摄条件 (比如时刻、季节、光照、天气) 下拍摄的，所以在亮度色泽等方面存在明显的不匹配问题。图像和谐化 (image harmonization) 旨在调整合成图中的前景，使其与背景和谐。传统的图像和谐化方法一般是从背景或者其他图片转移颜色信息到前景上，但这样无法保证调整之后的前景看起来真实并且与背景和谐。近年来，已经有少量的工作尝试用深度学习做图像和谐化，但成对的合成图和真实图极难获得。如果没有成对的合成图和真实图，深度学习的训练过程缺乏足够强的监督信息，合成图和谐化之后的结果也没有 ground-truth 用于评测。截至目前还没有公开的大规模图像和谐化数据库，我们**构建并公布了由四个子数据库组成的图像和谐化数据库。并且，我们提出了域验证 (domain verification) 的概念，尝试了基于域验证的图像和谐化算法。**<br><br>

### [3.PolarMask: 一阶段实例分割新思路](https://zhuanlan.zhihu.com/p/84890413)<br>

论文链接：https://arxiv.org/abs/1909.13226<br>
PolarMask基于FCOS，把实例分割统一到了FCN的框架下。FCOS本质上是一种FCN的dense prediction的检测框架，可以在性能上不输anchor based的目标检测方法，让行业看到了anchor free方法的潜力。接下来要解决的问题是实例分割。本工作最大的贡献在于把更复杂的实例分割问题，转化成在网络设计和计算量复杂度上和物体检测一样复杂的任务，把对实例分割的建模变得简单和高效。<br><br>

### [2.华为GhostNet，超越谷歌MobileNet，已开源](https://mp.weixin.qq.com/s/Wg_BQpo_3K_fumeelDvUxA)<br>

论文链接：https://arxiv.org/abs/1911.11907<br>
该论文提供了一个全新的Ghost模块，旨在通过廉价操作生成更多的特征图。基于一组原始的特征图，作者应用一系列线性变换，以很小的代价生成许多能从原始特征发掘所需信息的“幻影”特征图（Ghost feature maps）。该Ghost模块即插即用，通过堆叠Ghost模块得出Ghost bottleneck，进而搭建轻量级神经网络——GhostNet。在ImageNet分类任务，GhostNet在相似计算量情况下Top-1正确率达75.7%，高于MobileNetV3的75.2%。<br><br>

### [1.加州理工大学Devi Parikh：多任务视觉和语言表示学习](https://mp.weixin.qq.com/s/8CvUT9JvnysIXay7vyY16w)<br>

论文链接：https://arxiv.org/abs/1912.02315<br>
许多视觉和语言的研究集中在一组小而多样的独立任务和支持的数据集上，这些数据集通常是单独研究的;然而，成功完成这些任务所需的视觉语言理解技能有很大的重叠。在这项工作中，我们通过开发一个大规模的、多任务的训练机制来研究视觉和语言任务之间的关系。<br><br>


<br><br>

<a name="103"/>

# 4.To do list<br>
* CVPR2020复现代码及时更新<br>
* CVPR2020论文分享跟进<br>

<br><br>

<a name="104"/>

# 5.Related links<br>
* [CVPR2019/2018/2017最全资料下载（论文／代码等)](https://github.com/extreme-assistant/cvpr2020/blob/master/README.md)<br>
* https://github.com/extreme-assistant/iccv2019<br><br>


# 6.CVPR2020 contributors Wechat Group<br>
为了让大家更好得进行交流，极市特别组建了贡献者群及作者微信群，欢迎加小助手微信（cv-mart，备注CVPR2020）进群。
