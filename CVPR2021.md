* 推荐阅读：<br>
  * [2020-2021年计算机视觉综述论文汇总](https://github.com/extreme-assistant/survey-computer-vision)<br>
  * [国内外优秀的计算机视觉团队汇总](https://github.com/extreme-assistant/Awesome-CV-Team)
------

# CVPR2021最新信息及论文下载贴（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）

官网链接：http://cvpr2021.thecvf.com<br>
时间：2021年6月19日-6月25日<br>
论文接收公布时间：2021年2月28日<br>

相关问题：<br>

* [如何评价CVPR 2021的论文接收结果？](https://www.zhihu.com/question/446299297)<br>
* [CVPR 2021接收结果出炉！录用1663篇，接受率提升，你的论文中了吗？（附论文下载）](https://mp.weixin.qq.com/s/4UQ2W1V-eLnL02L8BDOtMg)

<br><br>

# 目录

[1. CVPR2021接受论文/代码分方向汇总（持续更新）](#1)<br>
[2. CVPR2021 Oral](#2)<br>
[3. To do list](#3)<br>


<br>

<a name="1"/> 

# 1.CVPR2021接受论文/代码分方向整理(持续更新)


## 分类目录：

### [1. 检测](#detection)
* [图像目标检测(Image Object Detection)](#IOD)<br>
* [视频目标检测(Video Object Detection)](#VOD)<br>
* [三维目标检测(3D Object Detection)](#3DOD)<br>
* [动作检测(Activity Detection)](#ActivityDetection)<br>
* [异常检测(Anomally Detection)](#AnomallyDetection)<br>
* [人物交互检测(HOI Detection)](#HOI)<br>
* [伪装目标检测(Camouflaged Object Detection)](#COD)<br>

### [2. 图像分割(Image Segmentation)](#ImageSegmentation)
* [全景分割(Panoptic Segmentation)](#PanopticSegmentation)<br>
* [语义分割(Semantic Segmentation)](#SemanticSegmentation)<br>
* [实例分割(Instance Segmentation)](#InstanceSegmentation)<br>
* [抠图(Matting)](#Matting)<br>

### [3. 图像处理(Image Processing)](#ImageProcessing)

* [图像复原(Image Restoration)/超分辨率(Super Resolution)](#ImageRestoration)
* [图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)](#ISR)
* [图像去噪/去模糊/去雨去雾(Image Denoising)](#ImageDenoising)
* [图像编辑/修复(Image Edit/Image Inpainting)](#ImageEdit)
* [图像翻译(Image Translation)](#ImageTranslation))

### [4. 估计(Estimation)](#Estimation)
* [人体姿态估计(Human Pose Estimation)](#HumanPoseEstimation)
* [手势估计(Gesture Estimation)](#GestureEstimation)
* [光流/位姿/运动估计(Flow/Pose/Motion Estimation)](#Flow/Pose/MotionEstimation)
* [深度估计(Depth Estimation)](#DepthEstimation)

### [5. 图像/视频检索(Image Retrieval)](#ImageRetrieval)
* [行为识别/动作识别(Action/Activity Recognition)](#ActionRecognition)
* [重识别(Re-Identification)](#Re-Identification)


### [6. 人脸(Face)](#Face)

### [7. 目标跟踪(Object Tracking)](#ObjectTracking)

### [8. 医学影像(Medical Imaging)](#MedicalImaging)

### [9. 文本检测/识别(Text Detection/Recognition)](#TDR)

### [10. 遥感图像(Remote Sensing Image)](#RSI)

### [11. GAN/生成式/对抗式(GAN/Generative/Adversarial)](#GAN)

### [12. 三维视觉(3D Vision)](#3DVision)
* [三维点云(3D Point Cloud)](#3DPC)<br>
* [三维重建(3D Reconstruction)](#3DReconstruction)<br>

### [13. 神经网络架构(Neural Network Structure)](#NNS)
* [Transformer](#Transformer)<br>
* [图神经网络(GNN)](#GNN)<br>

### [14. 神经网络架构搜索(NAS)](#NAS)

### [15. 数据处理(Data Processing)](#DataProcessing)
* [数据增广(Data Augmentation)](#DataAugmentation)<br>
* [表征学习(Representation Learning)](#RepresentationLearning)<br>
* [归一化/正则化(Batch Normalization)](#BatchNormalization)<br>
* [图像聚类(Image Clustering)](#ImageClustering)<br>

### [16. 模型压缩(Model Compression)](#ModelCompression)
* [知识蒸馏(Knowledge Distillation)](#KnowledgeDistillation)<br>

### [17. 模型评估(Model Evaluation)](#ModelEvaluation)

### [18. 数据集(Database)](#Database)

### [19. 主动学习(Active Learning)](#ActiveLearning)

### [20. 小样本/零样本学习(Few-shot/Zero-shot Learning)](#Few-shotLearning)

### [21. 持续学习(Continual Learning/Life-long Learning)](#ContinualLearning)

### [22. 视觉推理(Visual Reasoning)](#VisualReasoning)

### [23. 迁移学习/domain/自适应](#domain)

### [24. 对比学习(Contrastive Learning)](#ContrastiveLearning)

### [25. 强化学习(Reinforcement Learning)](#RL)

### [暂无分类](#100)



<br><br>

<a name="detection"/> 

## 检测


<a name="IOD"/> 

### 图像目标检测(Image Object Detection)

[9] MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection(用于类别识别无监督域自适应对象检测)<br>
[paper](https://arxiv.org/pdf/2103.04224.pdf)<br><br>

[8] OPANAS: One-Shot Path Aggregation Network Architecture Search for Object(一键式路径聚合网络体系结构搜索对象)<br>
[paper](https://arxiv.org/abs/2103.04507)|[code](https://github.com/VDIGPKU/OPANAS)<br><br>

[7] Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection(小样本目标检测的语义关系推理)<br>
[paper](https://arxiv.org/abs/2103.01903)<br><br>

[6] General Instance Distillation for Object Detection(通用实例蒸馏技术在目标检测中的应用)<br>
[paper](https://arxiv.org/abs/2103.02340)<br><br>

[5] Instance Localization for Self-supervised Detection Pretraining(自监督检测预训练的实例定位)<br>
[paper](https://arxiv.org/pdf/2102.08318.pdf)｜[code](https://github.com/limbo0000/InstanceLoc)<br><br>

[4] Multiple Instance Active Learning for Object Detection（用于对象检测的多实例主动学习）<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

[3] Towards Open World Object Detection(开放世界中的目标检测)<br>
[paper](https://arxiv.org/abs/2103.02603)|[code](https://github.com/JosephKJ/OWOD)<br><br>

[2] Positive-Unlabeled Data Purification in the Wild for Object Detection(野外检测对象的阳性无标签数据提纯)<br><br>

[1] UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)|[code](https://github.com/dddzg/up-detr)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>


<a name="VOD"/> 

### 视频目标检测(Video Object Detection)

[3] Depth from Camera Motion and Object Detection(相机运动和物体检测的深度)<br>
[paper](https://arxiv.org/abs/2103.01468)<br><br>

[2] There is More than Meets the Eye: Self-Supervised Multi-Object Detection  and Tracking with Sound by Distilling Multimodal Knowledge(多模态知识提取的自监督多目标检测与有声跟踪)<br>
[paper](https://arxiv.org/abs/2103.01353)|[video](https://www.youtube.com/channel/UCRpM8k1GY3kD2TqCo_yKN3g)|[project](http://rl.uni-freiburg.de/research/multimodal-distill)<br><br>

[1] Dogfight: Detecting Drones from Drone Videos（从无人机视频中检测无人机）<br><br>

<a name="3DOD"/> 

### 三维目标检测(3D object detection)

[2] 3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection(利用IoU预测进行半监督3D对象检测)<br>
[paper](https://arxiv.org/pdf/2012.04355.pdf)|[code](https://github.com/THU17cyz/3DIoUMatch)|[project](https://thu17cyz.github.io/3DIoUMatch/)|[video](https://youtu.be/nuARjhkQN2U)<br><br>

[1] Categorical Depth Distribution Network for Monocular 3D Object Detection(用于单目三维目标检测的分类深度分布网络)<br>
[paper](https://arxiv.org/abs/2103.01100)<br><br>

<a name="ActivityDetection"/> 

### 动作检测(Activity Detection)

[1] Coarse-Fine Networks for Temporal Activity Detection in Videos<br>
[paper](https://arxiv.org/abs/2103.01302)<br><br>

<a name="AnomallyDetection"/> 

### 异常检测(Anomally Detection)

[1] Multiresolution Knowledge Distillation for Anomaly Detection(用于异常检测的多分辨率知识蒸馏)<br>
[paper](https://arxiv.org/abs/2011.11108)<br><br>

<a name="HOI"/> 

### 人物交互检测(HOI Detection)

[1] End-to-End Human Object Interaction Detection with HOI Transformer(使用HOI Transformer进行端到端的人类对象交互检测)<br>
[paper](https://arxiv.org/pdf/2103.04503.pdf)|[code](https://github.com/bbepoch/HoiTransformer)<br><br>

<a name="COD"/> 

### 伪装目标检测(Camouflaged Object Detection)

[1] Simultaneously Localize, Segment and Rank the Camouflaged Objects(同时定位，分割和排序伪装的对象)<br>
[paper](https://arxiv.org/abs/2103.04011)|[code](https://github.com/JingZhang617/COD-Rank-Localize-and-Segment)<br><br>

<br>

<a name="ImageSegmentation"/> 

## 图像分割(Image Segmentation)


[2] Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?<br>
[paper](https://arxiv.org/abs/2012.06166)|[code](https://github.com/mboudiaf/RePRI-for-Few-Shot-Segmentation)<br><br>

[1] PointFlow: Flowing Semantics Through Points for Aerial Image Segmentation(语义流经点以进行航空图像分割)<br><br>

<a name="PanopticSegmentation"/> 

### 全景分割(Panoptic Segmentation)

[2] Cross-View Regularization for Domain Adaptive Panoptic Segmentation(用于域自适应全景分割的跨视图正则化)<br>
[paper](https://arxiv.org/abs/2103.02584)<br><br>

[1] 4D Panoptic LiDAR Segmentation（4D全景LiDAR分割）<br>
[paper](https://arxiv.org/abs/2102.12472)<br><br>

<a name="SemanticSegmentation"/> 

### 语义分割(Semantic Segmentation)

[5] Learning Statistical Texture for Semantic Segmentation(学习用于语义分割的统计纹理)<br>
[paper](https://arxiv.org/abs/2103.04133)<br><br>

[4] Semi-supervised Domain Adaptation based on Dual-level Domain Mixing for Semantic Segmentation(基于双层域混合的半监督域自适应语义分割)<br>
[paper](https://arxiv.org/pdf/2103.04705.pdf)<br><br>

[3] Multi-Source Domain Adaptation with Collaborative Learning for Semantic Segmentation(多源领域自适应与协作学习的语义分割)<br>
[paper](https://arxiv.org/abs/2103.04717)<br><br>

[2] Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges(走向城市规模3D点云的语义分割：数据集，基准和挑战)<br>
[paper](https://arxiv.org/abs/2009.03137)|[code](https://github.com/QingyongHu/SensatUrban)<br><br>

[1] PLOP: Learning without Forgetting for Continual Semantic Segmentation（PLOP：学习而不会忘记连续的语义分割）<br>
[paper](https://arxiv.org/abs/2011.11390)<br><br>

<a name="InstanceSegmentation"/> 

### 实例分割(Instance Segmentation)

[1] End-to-End Video Instance Segmentation with Transformers(使用Transformer的端到端视频实例分割) <br>
[paper](https://arxiv.org/abs/2011.14503)
<br><br>

<a name="Matting"/> 

## 抠图(Matting)

[1] Real-Time High Resolution Background Matting<br>
[paper](https://arxiv.org/abs/2012.07810)|[code](https://github.com/PeterL1n/BackgroundMattingV2)|[project](https://grail.cs.washington.edu/projects/background-matting-v2/)|[video](https://youtu.be/oMfPTeYDF9g)<br><br>

<a name="Estimation"/> 

## 9. 估计(Estimation)

<a name="HumanPoseEstimation"/> 

### 人体姿态估计(Human Pose Estimation)

[3] Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing(用于实例感知人类语义解析的可微分多粒度人类表示学习)<br>
[paper](https://arxiv.org/pdf/2103.04570.pdf)|[code](https://github.com/tfzhou/MG-HumanParsing)<br><br>

[2] CanonPose: Self-supervised Monocular 3D Human Pose Estimation in the Wild（野外自监督的单眼3D人类姿态估计）<br><br>

[1] PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective Crop Layers（具有透视作物层的3D姿势的几何感知神经重建）<br>
[paper](https://arxiv.org/abs/2011.13607)<br><br>

<a name="GestureEstimation"/> 


### 手势估计(Gesture Estimation)

[1] Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive  2D-1D Registration(基于语义聚合和自适应2D-1D配准的相机空间手部网格恢复)<br>
[paper](https://arxiv.org/pdf/2103.02845.pdf)|[code](https://github.com/SeanChenxy/HandMesh)<br><br>

<a name="Flow/Pose/MotionEstimation"/> 

### 光流/位姿/运动估计(Flow/Pose/Motion Estimation)

[3] GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation(用于单眼6D对象姿态估计的几何引导直接回归网络)<br>
[paper](http://arxiv.org/abs/2102.12145)|[code](https://github.com/THU-DA-6D-Pose-Group/GDR-Net)<br><br>

[2] Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments(在动态室内环境中，通过空间划分的鲁棒神经路由可实现摄像机的重新定位)<br>
[paper](https://arxiv.org/abs/2012.04746)|[project](https://ai.stanford.edu/~hewang/)<br><br>

[1] MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization(通过3D扫描同步进行多主体分割和运动估计)<br>
[paper](https://arxiv.org/pdf/2101.06605.pdf)|[code](https://github.com/huangjh-pub/multibody-sync)<br><br>

<a name="DepthEstimation"/> 

### 深度估计(Depth Estimation)

<br>

<a name="ImageProcessing"/> 

## 图像处理(Image Processing)



<a name="ImageRestoration"/> 

###  图像复原(Image Restoration)/超分辨率(Super Resolution)

[5] ClassSR: A General Framework to Accelerate Super-Resolution Networks by Data Characteristic(通过数据特征加速超分辨率网络的通用框架)<br>
[paper](https://arxiv.org/abs/2103.04039)<br><br>

[4] Learning Continuous Image Representation with Local Implicit Image Function(通过局部隐含图像功能学习连续图像表示)<br>
[paepr](https://arxiv.org/abs/2012.09161)|[code](https://github.com/yinboc/liif)|[video](https://youtu.be/6f2roieSY_8)|[project](https://yinboc.github.io/liif/)<br><br>

[3] Multi-Stage Progressive Image Restoration(多阶段渐进式图像复原)<br>
[paper](https://arxiv.org/abs/2102.02808)|[code](https://github.com/swz30/MPRNet)<br><br>

[2] Data-Free Knowledge Distillation For Image Super-Resolution(DAFL算法的SR版本)<br><br>

[1] AdderSR: Towards Energy Efficient Image Super-Resolution(将加法网路应用到图像超分辨率中)<br>
[paper](https://arxiv.org/pdf/2009.08891.pdf)|[code](https://github.com/huawei-noah/AdderNet)<br>
解读：[华为开源加法神经网络](https://zhuanlan.zhihu.com/p/113536045)<br><br>




<a name="ISR"/> 

### 图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)

[2] Robust Reflection Removal with Reflection-free Flash-only Cues(通过无反射的仅含Flash线索进行鲁棒的反射去除)<br>
[paper](https://arxiv.org/pdf/2103.04273.pdf)|[code](https://github.com/ChenyangLEI/flash-reflection-removal)<br><br>

[1] Auto-Exposure Fusion for Single-Image Shadow Removal(用于单幅图像阴影去除的自动曝光融合)<br>
[paper](https://arxiv.org/abs/2103.01255)|[code](https://github.com/tsingqguo/exposure-fusion-shadow-removal)<br><br>



<a name="ImageDenoising"/> 

### 图像去噪/去模糊/去雨去雾(Image Denoising)

[2] ARVo: Learning All-Range Volumetric Correspondence for Video Deblurring(学习用于视频去模糊的全范围体积对应)<br>
[paper](https://arxiv.org/pdf/2103.04260.pdf)<br><br>

[1] DeFMO: Deblurring and Shape Recovery of Fast Moving Objects(快速移动物体的去模糊和形状恢复)<br>
[paper](https://arxiv.org/abs/2012.00595)|[code](https://github.com/rozumden/DeFMO)|[video](https://www.youtube.com/watch?v=pmAynZvaaQ4)<br><br>

<a name="ImageEdit"/> 

### 图像编辑/图像修复(Image Edit/Inpainting)

[5] PISE: Person Image Synthesis and Editing with Decoupled GAN(使用分离的GAN进行人像合成和编辑)<br>
[paper](https://arxiv.org/abs/2103.04023)|[code](https://github.com/Zhangjinso/PISE)<br><br>

[4] DeFLOCNet: Deep Image Editing via Flexible Low level Controls(通过灵活的低级控件进行深度图像编辑)<br><br>

[3] PD-GAN: Probabilistic Diverse GAN for Image Inpainting(用于图像修复的概率多样GAN)<br><br>

[2] Anycost GANs for Interactive Image Synthesis and Editing(用于交互式图像合成和编辑的AnyCost Gans)<br>
[paper](https://arxiv.org/abs/2103.03243)|[code](https://github.com/mit-han-lab/anycost-gan)<br><br>

[1] Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing（利用GAN中潜在的空间维度进行实时图像编辑）<br><br>



<a name="ImageTranslation"/> 

### 图像翻译（Image Translation）

[3] Spatially-Adaptive Pixelwise Networks for Fast Image Translation(空间自适应像素网络，用于快速图像翻译)<br>
[paper](https://arxiv.org/abs/2012.02992)|[project](https://tamarott.github.io/ASAPNet_web/)<br><br>

[2] Image-to-image Translation via Hierarchical Style Disentanglement<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

[1] Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(样式编码：用于图像到图像翻译的StyleGAN编码器)<br>
[paper](https://arxiv.org/abs/2008.00951)|[code](https://github.com/eladrich/pixel2style2pixel)|[project](https://eladrich.github.io/pixel2style2pixel/)<br><br>

<br>

<a name="Face"/> 

## 人脸(Face)

[8] Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders(分析和改进自省变分自动编码器)<br>
[paper](https://arxiv.org/pdf/2012.13253.pdf)|[code](https://github.com/taldatech/soft-intro-vae-pytorch)|[project](https://taldatech.github.io/soft-intro-vae-web/)<br><br>

[7] PISE: Person Image Synthesis and Editing with Decoupled GAN(使用分离的GAN进行人像合成和编辑)<br>
[paper](https://arxiv.org/abs/2103.04023)|[code](https://github.com/Zhangjinso/PISE)<br><br>

[6] WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition(揭示了百万级深度人脸识别力量的基准测试)<br>
[paper](https://arxiv.org/abs/2103.04098)|[benchmark](https://www.face-benchmark.org/)<br><br>

[5] Cross Modal Focal Loss for RGBD Face Anti-Spoofing(跨模态焦点损失，用于RGBD人脸反欺骗)
[paper](https://arxiv.org/abs/2103.00948)<br><br>

[4] When Age-Invariant Face Recognition Meets Face Age Synthesis: A  Multi-Task Learning Framework(当年龄不变的人脸识别遇到人脸年龄合成时：一个多任务学习框架)<br>
[paper](https://arxiv.org/abs/2103.01520)|[code](https://github.com/Hzzone/MTLFace)<br><br>

[3] Multi-attentional Deepfake Detection(多注意的深伪检测)<br>
[paper](https://arxiv.org/abs/2103.02406)<br><br>

[2] Image-to-image Translation via Hierarchical Style Disentanglement<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

[1] A 3D GAN for Improved Large-pose Facial Recognition(用于改善大姿势面部识别的3D GAN)<br>
[paper](https://arxiv.org/pdf/2012.10545.pdf)<br><br>

<br>

<a name="ObjectTracking"/> 

## 目标跟踪(Object Tracking)

[4] HPS: localizing and tracking people in large 3D scenes from wearable sensors(通过可穿戴式传感器对大型3D场景中的人进行定位和跟踪)<br><br>

[3] Track to Detect and Segment: An Online Multi-Object Tracker(跟踪检测和分段：在线多对象跟踪器)<br>
[project](https://jialianwu.com/projects/TraDeS.html)|[video](https://www.youtube.com/watch?v=oGNtSFHRZJA)<br><br>

[2] Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking(多目标跟踪的概率小波计分和修复)<br>
[paper](https://arxiv.org/abs/2012.02337)<br><br>

[1] Rotation Equivariant Siamese Networks for Tracking（旋转等距连体网络进行跟踪）<br>
[paper](https://arxiv.org/abs/2012.13078)<br><br>


<br><br>
<a name="ImageRetrieval"/> 

## 图像/视频检索(Image/Video Retrieval)

[1] QAIR: Practical Query-efficient Black-Box Attacks for Image Retrieval(实用的查询高效的图像检索黑盒攻击)<br>
[paper](https://arxiv.org/abs/2103.02927)<br><br>


<a name="ActionRecognition"/> 

### 行为识别/动作识别(Action/Activity Recognition)

[1] Behavior-Driven Synthesis of Human Dynamics(行为驱动的人类动力学综合)<br>
[paper](https://arxiv.org/pdf/2103.04677.pdf)|[code](https://compvis.github.io/behavior-driven-video-synthesis/)<>


<a name="Re-Identification"/> 

### 重识别

[3] Watching You: Global-guided Reciprocal Learning for Video-based Person Re-identification(基于视频的人员重新识别的全球指导对等学习)<br>
[paper](https://arxiv.org/abs/2103.04337)<br><br>

[2] Joint Noise-Tolerant Learning and Meta Camera Shift Adaptation for Unsupervised Person Re-Identification(联合抗噪学习和元相机移位自适应，用于无监督人员的重新识别)<br>
[paper](https://arxiv.org/abs/2103.04618)<br><br>

[1] Meta Batch-Instance Normalization for Generalizable Person Re-Identification(通用批处理人员重新标识的元批实例规范化)<br>
[paper](https://arxiv.org/abs/2011.14670)<br><br>

<br>

<a name="MedicalImaging"/> 

## 医学影像(Medical Imaging)

[5] DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on  Cardiac Tagging Magnetic Resonance Images(一种心脏标记磁共振图像运动跟踪的无监督深度学习方法)<br>
[paper](https://arxiv.org/abs/2103.02772)<br><br>

[4] Multi-institutional Collaborations for Improving Deep Learning-based Magnetic Resonance Image Reconstruction Using Federated Learning(多机构协作改进基于深度学习的联合学习磁共振图像重建)<br>
[paper](https://arxiv.org/abs/2103.02148)|[code](https://github.com/guopengf/FLMRCM)<br><br>

[3] 3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management(用于胰腺肿块分割，诊断和定量患者管理的3D图形解剖学几何集成网络)<br><br>

[2] Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging Studies(深部病变追踪器：在4D纵向成像研究中监控病变)<br>
[paper](https://arxiv.org/abs/2012.04872)<br><br>

[1] Automatic Vertebra Localization and Identification in CT by Spine Rectification and Anatomically-constrained Optimization(通过脊柱矫正和解剖学约束优化在CT中自动进行椎骨定位和识别)<br>
[paper](https://arxiv.org/abs/2012.07947)<br><br>

<br>

<a name="TDR"/> 


## 文本检测/识别(Text Detection/Recognition)

[1] What If We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels(如果我们仅将真实数据集用于场景文本识别该怎么办？ 带有较少标签的场景文本识别)<br>
[paepr](https://arxiv.org/abs/2103.04400)|[code](https://github.com/ku21fan/STR-Fewer-Labels)<br><br>

<br>

<a name="RSI"/> 

## 遥感图像(Remote Sensing Image)

[1] Deep Gradient Projection Networks for Pan-sharpening(【超分辨率】泛锐化的深梯度投影网络)<br>
[paper](https://arxiv.org/pdf/2103.04584.pdf)|[code](https://github.com/xsxjtu/GPPNN)<br><br>

<br>

<a name="NAS"/> 

## 神经网络架构搜索(NAS)

[4] OPANAS: One-Shot Path Aggregation Network Architecture Search for Object(一键式路径聚合网络体系结构搜索对象)<br>
[paper](https://arxiv.org/abs/2103.04507)|[code](https://github.com/VDIGPKU/OPANAS)<br><br>

[3] AttentiveNAS: Improving Neural Architecture Search via Attentive(通过注意力改善神经架构搜索) <br>
[paper](https://arxiv.org/pdf/2011.09011.pdf)<br><br>

[2] ReNAS: Relativistic Evaluation of Neural Architecture Search(NAS predictor当中ranking loss的重要性)<br>
[paper](https://arxiv.org/pdf/1910.01523.pdf)<br><br>

[1] HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens（降低NAS的成本）<br>
[paper](https://arxiv.org/pdf/2005.14446.pdf)<br><br>

<br>

<a name="GAN"/> 

## GAN/生成式/对抗式(GAN/Generative/Adversarial)

[11] Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders(分析和改进自省变分自动编码器)<br>
[paper](https://arxiv.org/pdf/2012.13253.pdf)|[code](https://github.com/taldatech/soft-intro-vae-pytorch)|[project](https://taldatech.github.io/soft-intro-vae-web/)<br><br>

[10] LOHO: Latent Optimization of Hairstyles via Orthogonalization(LOHO：通过正交化潜在地优化发型)<br>
[paper](https://arxiv.org/pdf/2103.03891.pdf)<br><br>

[9] PISE: Person Image Synthesis and Editing with Decoupled GAN(使用分离的GAN进行人像合成和编辑)<br>
[paper](https://arxiv.org/abs/2103.04023)|[code](https://github.com/Zhangjinso/PISE)<br><br>

[8] Closed-Form Factorization of Latent Semantics in GANs(GAN中潜在语义的闭式分解)<br>
[paper](https://arxiv.org/abs/2007.06600)|[code](https://github.com/genforce/sefa)<br><br>

[7] PD-GAN: Probabilistic Diverse GAN for Image Inpainting(用于图像修复的概率多样GAN)<br><br>

[6] Anycost GANs for Interactive Image Synthesis and Editing(用于交互式图像合成和编辑的AnyCost Gans)<br>
[paper](https://arxiv.org/abs/2103.03243)|[code](https://github.com/mit-han-lab/anycost-gan)<br><br>

[5] Efficient Conditional GAN Transfer with Knowledge Propagation across Classes(高效的有条件GAN转移以及跨课程的知识传播)<br>
[paper](高效的有条件GAN转移以及跨课程的知识传播)|[code](http://github.com/mshahbazi72/cGANTransfer)<br><br>

[4] Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing（利用GAN中潜在的空间维度进行实时图像编辑）<br><br>

[3] Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs(Hijack-GAN：意外使用经过预训练的黑匣子GAN)<br>
[paper](https://arxiv.org/pdf/2011.14107.pdf)<br><br>

[2] Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(样式编码：用于图像到图像翻译的StyleGAN编码器)<br>
[paper](https://arxiv.org/abs/2008.00951)|[code](https://github.com/eladrich/pixel2style2pixel)|[project](https://eladrich.github.io/pixel2style2pixel/)<br><br>

[1] A 3D GAN for Improved Large-pose Facial Recognition(用于改善大姿势面部识别的3D GAN)<br>
[paper](https://arxiv.org/pdf/2012.10545.pdf)<br><br>

<br>

<a name="3DVision"/> 

## 三维视觉(3D Vision)

[2] A Deep Emulator for Secondary Motion of 3D Characters(三维角色二次运动的深度仿真器)
[paper](https://arxiv.org/abs/2103.01261)

[1] 3D CNNs with Adaptive Temporal Feature Resolutions(具有自适应时间特征分辨率的3D CNN)<br>
[paper](https://arxiv.org/abs/2011.08652)<br><br>

<a name="3DPC"/> 

### 点云(Point Cloud)

[9] Robust Point Cloud Registration Framework Based on Deep Graph Matching(基于深度图匹配的鲁棒点云配准框架)<br>
[paper](https://arxiv.org/pdf/2103.04256.pdf)|[code](https://github.com/fukexue/RGM)<br><br>

[8] TPCN: Temporal Point Cloud Networks for Motion Forecasting(面向运动预测的时态点云网络)
[paper](https://arxiv.org/abs/2103.03067)|[code]()

[7] PointGuard: Provably Robust 3D Point Cloud Classification(可证明稳健的三维点云分类)<br>
[paper](https://arxiv.org/abs/2103.03046)<br><br>

[6] Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges(走向城市规模3D点云的语义分割：数据集，基准和挑战)<br>
[paper](https://arxiv.org/abs/2009.03137)|[code](https://github.com/QingyongHu/SensatUrban)<br><br>

[5] SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration(SpinNet：学习用于3D点云配准的通用表面描述符)<br>
[paper](https://t.co/xIAWVGQeB2?amp=1)|[code](https://github.com/QingyongHu/SpinNet)<br><br>

[4] MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization(通过3D扫描同步进行多主体分割和运动估计)<br>
[paper](https://arxiv.org/pdf/2101.06605.pdf)|[code](https://github.com/huangjh-pub/multibody-sync)<br><br>

[3] Diffusion Probabilistic Models for 3D Point Cloud Generation(三维点云生成的扩散概率模型)<br>
[paper](https://arxiv.org/abs/2103.01458)|[code](https://github.com/luost26/diffusion-point-cloud)<br><br>

[2] Style-based Point Generator with Adversarial Rendering for Point Cloud Completion(用于点云补全的对抗性渲染基于样式的点生成器)<br>
[paper](https://arxiv.org/abs/2103.02535)

[1] PREDATOR: Registration of 3D Point Clouds with Low Overlap(预测器：低重叠的3D点云的配准)<br>
[paper](https://arxiv.org/pdf/2011.13005.pdf)|[code](https://github.com/ShengyuH/OverlapPredator)|[project](https://overlappredator.github.io/)<br><br>


<a name="3DReconstruction"/> 

### 三维重建(3D Reconstruction)

[1] PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective Crop Layers（具有透视作物层的3D姿势的几何感知神经重建）<br>
[paper](https://arxiv.org/abs/2011.13607)<br><br>

<br>

<a name="ModelCompression"/> 

## 模型压缩(Model Compression)

[2] Manifold Regularized Dynamic Network Pruning（动态剪枝的过程中考虑样本复杂度与网络复杂度的约束）<br><br>

[1] Learning Student Networks in the Wild（一种不需要原始训练数据的模型压缩和加速技术）<br>
[paper](https://arxiv.org/pdf/1904.01186.pdf)|[code](https://github.com/huawei-noah/DAFL)<br>
解读：[华为诺亚方舟实验室提出无需数据网络压缩技术](https://zhuanlan.zhihu.com/p/81277796)<br><br>

<a name="KnowledgeDistillation"/> 

### 知识蒸馏(Knowledge Distillation)
[5] Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning(少班级增量学习的语义感知知识蒸馏)<br>
[paper](https://arxiv.org/abs/2103.04059)<br><br>

[4] Teachers Do More Than Teach: Compressing Image-to-Image Models(https://arxiv.org/abs/2103.03467)<br>
[paper](https://arxiv.org/abs/2103.03467)|[code](https://github.com/snap-research/CAT)<br><br>

[3] General Instance Distillation for Object Detection(通用实例蒸馏技术在目标检测中的应用)<br>
[paper](https://arxiv.org/abs/2103.02340)<br><br>

[2] Multiresolution Knowledge Distillation for Anomaly Detection(用于异常检测的多分辨率知识蒸馏)<br>
[paper](https://arxiv.org/abs/2011.11108)<br><br>

[1] Distilling Object Detectors via Decoupled Features（前景背景分离的蒸馏技术） <br><br>

<br>

<a name="NNS"/> 

## 神经网络架构(Neural Network Structure)

[4] Coordinate Attention for Efficient Mobile Network Design(协调注意力以实现高效的移动网络设计)<br>
[paper](https://arxiv.org/abs/2103.02907)<br><br>

[3] Rethinking Channel Dimensions for Efficient Model Design(重新考虑通道尺寸以进行有效的模型设计)<br>
[paper](https://arxiv.org/abs/2007.00992)|[code](https://github.com/clovaai/rexnet)<br><br>

[2] Inverting the Inherence of Convolution for Visual Recognition（颠倒卷积的固有性以进行视觉识别）<br><br>

[1] RepVGG: Making VGG-style ConvNets Great Again<br>
[paper](https://arxiv.org/abs/2101.03697)|[code](https://github.com/megvii-model/RepVGG)<br>
解读：[RepVGG：极简架构，SOTA性能，让VGG式模型再次伟大](https://zhuanlan.zhihu.com/p/344324470)<br><br>

<a name="Transformer"/> 

### Transformer

[3] Transformer Interpretability Beyond Attention Visualization(注意力可视化之外的Transformer可解释性)<br>
[paper](https://arxiv.org/pdf/2012.09838.pdf)|[code](https://github.com/hila-chefer/Transformer-Explainability)<br><br>

[2] UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)|[code](https://github.com/dddzg/up-detr)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>

[1] Pre-Trained Image Processing Transformer(底层视觉预训练模型)<br>
[paper](https://arxiv.org/pdf/2012.00364.pdf)<br><br>

<a name="GNN"/> 

### 图神经网络(GNN)

[2] Quantifying Explainers of Graph Neural Networks in Computational Pathology(计算病理学中图神经网络的量化解释器)<br>
[paper](https://arxiv.org/pdf/2011.12646.pdf)<br><br>

[1] Sequential Graph Convolutional Network for Active Learning(主动学习的顺序图卷积网络)<br>
[paper](https://arxiv.org/pdf/2006.10219.pdf)<br><br>


<br>

<a name="DataProcessing"/> 

## 数据处理(Data Processing)

<a name="DataAugmentation"/> 

### 数据增广(Data Augmentation)

[1] KeepAugment: A Simple Information-Preserving Data Augmentation(一种简单的保存信息的数据扩充)<br>
[paper](https://arxiv.org/pdf/2011.11778.pdf)<br><br>

<a name="RepresentationLearning"/> 

### 表征学习(Representation Learning)

[1] VirTex: Learning Visual Representations from Textual Annotations（【表示学习】从文本注释中学习视觉表示）<br>
[paper](https://arxiv.org/abs/2006.06666)|[code](https://github.com/kdexd/virtex)<br><br>

<a name="BatchNormalization"/> 

### 归一化/正则化(Batch Normalization)

[3] Adaptive Consistency Regularization for Semi-Supervised Transfer Learning(半监督转移学习的自适应一致性正则化)<br>
[paper](https://arxiv.org/abs/2103.02193)|[code](https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning)

[2] Meta Batch-Instance Normalization for Generalizable Person Re-Identification(通用批处理人员重新标识的元批实例规范化)<br>
[paper](https://arxiv.org/abs/2011.14670)<br><br>

[1] Representative Batch Normalization with Feature Calibration（具有特征校准功能的代表性批量归一化）<br><br>

<a name="ImageClustering"/> 

### 图像聚类(Image Clustering)

[2] Improving Unsupervised Image Clustering With Robust Learning（通过鲁棒学习改善无监督图像聚类）<br>
[paper](https://arxiv.org/abs/2012.11150)|[code](https://github.com/deu30303/RUC)<br><br>

[1] Reconsidering Representation Alignment for Multi-view Clustering(重新考虑多视图聚类的表示对齐方式)<br><br>

<br>

<a name="ModelEvaluation"/> 

## 模型评估(Model Evaluation)

[1] Are Labels Necessary for Classifier Accuracy Evaluation?(测试集没有标签，我们可以拿来测试模型吗？)<br>
[paper](https://arxiv.org/abs/2007.02915)|[解读](https://zhuanlan.zhihu.com/p/328686799)<br><br>


<br>

<a name="Database"/> 

## 数据集(Database)


[2] Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges(走向城市规模3D点云的语义分割：数据集，基准和挑战)<br>
[paper](https://arxiv.org/abs/2009.03137)|[code](https://github.com/QingyongHu/SensatUrban)<br><br>

[1] Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels（重新标记ImageNet：从单标签到多标签，从全局标签到本地标签）<br>
[paper](https://arxiv.org/abs/2101.05022)|[code](https://github.com/naver-ai/relabel_imagenet)<br><br>

<br>

<a name="ActiveLearning"/> 

## 主动学习(Active Learning)


[3] Vab-AL: Incorporating Class Imbalance and Difficulty with Variational Bayes for Active Learning<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

[2] Multiple Instance Active Learning for Object Detection（用于对象检测的多实例主动学习）<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

[1] Sequential Graph Convolutional Network for Active Learning(主动学习的顺序图卷积网络)<br>
[paper](https://arxiv.org/pdf/2006.10219.pdf)<br><br>

<br>

<a name="Few-shotLearning"/> 

## 小样本学习(Few-shot Learning)/零样本学习(Zero-shot Learning)

[6] Goal-Oriented Gaze Estimation for Zero-Shot Learning(零样本学习的目标导向注视估计)<br>
[paper](https://arxiv.org/abs/2103.03433)|[code](https://github.com/osierboy/GEM-ZSL)<br><br>

[5] Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?<br>
[paper](https://arxiv.org/abs/2012.06166)|[code](https://github.com/mboudiaf/RePRI-for-Few-Shot-Segmentation)<br><br>

[4] Counterfactual Zero-Shot and Open-Set Visual Recognition(反事实零射和开集视觉识别)<br>
[paper](https://arxiv.org/abs/2103.00887)|[code](https://github.com/yue-zhongqi/gcm-cf)<br><br>

[3] Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection(小样本目标检测的语义关系推理)<br>
[paper](https://arxiv.org/abs/2103.01903)<br><br>

[2] Few-shot Open-set Recognition by Transformation Consistency(转换一致性很少的开放集识别)<br><br>

[1] Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning(探索少量学习的不变表示形式和等变表示形式的互补强度)<br>
[paper](https://arxiv.org/abs/2103.01315)|<br>

<br>

<a name="ContinualLearning"/> 

## 持续学习(Continual Learning/Life-long Learning)

[2] Rainbow Memory: Continual Learning with a Memory of Diverse Samples（不断学习与多样本的记忆）<br><br>

[1] Learning the Superpixel in a Non-iterative and Lifelong Manner(以非迭代和终身的方式学习超像素)<br><br>


<br><br>

<a name="VisualReasoning"/> 

## 视觉推理(Visual Reasoning)

[1] Transformation Driven Visual Reasoning(转型驱动的视觉推理)<br>
[paper](https://arxiv.org/pdf/2011.13160.pdf)|[code](https://github.com/hughplay/TVR)|[project](https://hongxin2019.github.io/TVR/)<br>


<br><br>

<a name="domain"/> 

## 迁移学习/domain/自适应](#domain)

[6] Semi-supervised Domain Adaptation based on Dual-level Domain Mixing for Semantic Segmentation(基于双层域混合的半监督域自适应语义分割)<br>
[paper](https://arxiv.org/pdf/2103.04705.pdf)<br><br>

[5] Multi-Source Domain Adaptation with Collaborative Learning for Semantic Segmentation(多源领域自适应与协作学习的语义分割)<br>
[paper](https://arxiv.org/abs/2103.04717)<br><br>

[4] Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning(通过域随机化和元学习对视觉表示进行连续调整)<br>
[paper](https://arxiv.org/abs/2012.04324)<br><br>

[3] Domain Generalization via Inference-time Label-Preserving Target Projections(基于推理时间保标目标投影的区域泛化)<br>
[paper](https://arxiv.org/abs/2103.01134)<br><br>

[2] MetaSCI: Scalable and Adaptive Reconstruction for Video Compressive  Sensing(可伸缩的自适应视频压缩传感重建)<br>
[paper](https://arxiv.org/abs/2103.01786)|[code](https://github.com/xyvirtualgroup/MetaSCI-CVPR2021)<br><br>

[1] FSDR: Frequency Space Domain Randomization for Domain Generalization(用于域推广的频域随机化)<br>
[paper](https://arxiv.org/abs/2103.02370)<br><br>

<br><br>

<a name="ContrastiveLearning"/> 

## 对比学习(Contrastive Learning)

[1] Fine-grained Angular Contrastive Learning with Coarse Labels(粗标签的细粒度角度对比学习)<br>
[paper](https://arxiv.org/abs/2012.03515)<br><br>



<br><br>
<a name="RL"/> 

## 强化学习(Reinforcement Learning)

[1] Unsupervised Learning for Robust Fitting:A Reinforcement Learning Approach(无监督学习以进行稳健拟合：一种强化学习方法)<br><br>
[paper](https://arxiv.org/abs/2103.03501)<br><br>

<br><br>

<a name="100"/> 

## 暂无分类

Consensus Maximisation Using Influences of Monotone Boolean Functions(利用单调布尔函数的影响实现共识最大化)<br>
[paper](https://arxiv.org/pdf/2103.04200.pdf)<br><br>

Nutrition5k: Towards Automatic Nutritional Understanding of Generic Food(实现对通用食品的自动营养理解)<br>
[paper](https://arxiv.org/abs/2103.03375)<br><br>

Structured Scene Memory for Vision-Language Navigation(用于视觉语言导航的结构化场景存储器)<br>
[paper](https://arxiv.org/abs/2103.03454)|[code](https://github.com/HanqingWangAI/SSM-VLN)<br><br>

Learning Asynchronous and Sparse Human-Object Interaction in Videos(视频中异步稀疏人-物交互的学习)<br>
[paper](https://arxiv.org/abs/2103.02758)<br><br>

Self-supervised Geometric Perception(自我监督的几何知觉)<br>
[paper](https://arxiv.org/abs/2103.03114)<br><br>

Quantifying Explainers of Graph Neural Networks in Computational Pathology(计算病理学中图神经网络的量化解释器)<br>
[paper](https://arxiv.org/pdf/2011.12646.pdf)<br><br>

Exploring Data-Efficient 3D Scene Understanding with Contrastive Scene Contexts(探索具有对比场景上下文的数据高效3D场景理解)<br>
[paper](http://arxiv.org/abs/2012.09165)|[project](http://sekunde.github.io/project_efficient)|[video](http://youtu.be/E70xToZLgs4)<br><br>

Data-Free Model Extraction(无数据模型提取)<br>
[paper](https://arxiv.org/abs/2011.14779)<br>

Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition(用于【位置识别】的局部全局描述符的【多尺度融合】)<br>
[paper](https://arxiv.org/pdf/2103.01486.pdf)|[code](https://github.com/QVPR/Patch-NetVLAD)<br><br>

Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations(适用于正确概念的权利：通过可解释性来修正神经符号概念)<br>
[paper](https://arxiv.org/abs/2011.12854)<br><br>

Multi-Objective Interpolation Training for Robustness to Label Noise(多目标插值训练的鲁棒性)<br>
[paper](https://arxiv.org/abs/2012.04462)|[code](https://git.io/JI40X)<br><br>

VX2TEXT: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs(【文本生成】VX2TEXT：基于视频的文本生成的端到端学习来自多模式输入)<br>
[paper](https://arxiv.org/pdf/2101.12059.pdf)<br><br>

Scan2Cap: Context-aware Dense Captioning in RGB-D Scans(【图像字幕】Scan2Cap：RGB-D扫描中的上下文感知密集字幕)
[paper](https://arxiv.org/abs/2012.02206)|[code](https://github.com/daveredrum/Scan2Cap)|[project](https://daveredrum.github.io/Scan2Cap/)|[video](https://youtu.be/AgmIpDbwTCY)<br><br>

Hierarchical and Partially Observable Goal-driven Policy Learning with  Goals Relational Graph(基于目标关系图的分层部分可观测目标驱动策略学习)<br>
[paper](https://arxiv.org/abs/2103.01350)<br><br>

ID-Unet: Iterative Soft and Hard Deformation for View Synthesis(视图合成的迭代软硬变形)<br>
[paper](https://arxiv.org/abs/2103.02264)<br><br>

PML: Progressive Margin Loss for Long-tailed Age Classification(【长尾分布】【图像分类】长尾年龄分类的累进边际损失)<br>
[paper](https://arxiv.org/abs/2103.02140)<br><br>

Diversifying Sample Generation for Data-Free Quantization（【图像生成】多样化的样本生成，实现无数据量化）<br>
[paper](https://arxiv.org/abs/2103.01049)<br><br>

Domain Generalization via Inference-time Label-Preserving Target Projections（通过保留推理时间的目标投影进行域泛化）<br>
[paper](https://arxiv.org/pdf/2103.01134.pdf)<br><br>

DeRF: Decomposed Radiance Fields（分解的辐射场）<br>
[project](https://ubc-vision.github.io/derf/)<br><br>

Densely connected multidilated convolutional networks for dense prediction tasks（【密集预测】密集连接的多重卷积网络，用于密集的预测任务）<br>
[paper](https://arxiv.org/abs/2011.11844)<br><br>


Weakly-supervised Grounded Visual Question Answering using Capsules（使用胶囊进行弱监督的地面视觉问答）<br><br>

FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation（【视频插帧】FLAVR：用于快速帧插值的与流无关的视频表示）<br>
[paper](https://arxiv.org/pdf/2012.08512.pdf)|[code](https://tarun005.github.io/FLAVR/Code)|[project](https://tarun005.github.io/FLAVR/)<br><br>

Probabilistic Embeddings for Cross-Modal Retrieval（跨模态检索的概率嵌入）<br>
[paper](https://arxiv.org/abs/2101.05068)<br><br>

Self-supervised Simultaneous Multi-Step Prediction of Road Dynamics and Cost Map(道路动力学和成本图的自监督式多步同时预测)<br><br>

IIRC: Incremental Implicitly-Refined Classification(增量式隐式定义的分类)<br>
[paper](https://arxiv.org/abs/2012.12477)|[project](https://chandar-lab.github.io/IIRC/)<br><br>

Fair Attribute Classification through Latent Space De-biasing(通过潜在空间去偏的公平属性分类)<br>
[paper](https://arxiv.org/abs/2012.01469)|[code](https://github.com/princetonvisualai/gan-debiasing)|[project](https://princetonvisualai.github.io/gan-debiasing/)<br><br>

Information-Theoretic Segmentation by Inpainting Error Maximization(修复误差最大化的信息理论分割)<br>
[paper](https://arxiv.org/abs/2012.07287)<br><br>

UC2: Universal Cross-lingual Cross-modal Vision-and-Language Pretraining(【视频语言学习】UC2：通用跨语言跨模态视觉和语言预培训)<br><br>

Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling(通过稀疏采样进行视频和语言学习)<br>
[paper](https://arxiv.org/pdf/2102.06183.pdf)|[code](https://github.com/jayleicn/ClipBERT)<br><br>

D-NeRF: Neural Radiance Fields for Dynamic Scenes(D-NeRF：动态场景的神经辐射场)<br>
[paper](https://arxiv.org/abs/2011.13961)|[project](https://www.albertpumarola.com/research/D-NeRF/index.html)<br><br>

Weakly Supervised Learning of Rigid 3D Scene Flow(刚性3D场景流的弱监督学习)<br>
[paper](https://arxiv.org/pdf/2102.08945.pdf)|[code](https://arxiv.org/pdf/2102.08945.pdf)|[project](https://3dsceneflow.github.io/)<br><br>

<br>

<a name="2"/> 

## 2. CVPR2021 Oral

[29] Consensus Maximisation Using Influences of Monotone Boolean Functions(利用单调布尔函数的影响实现共识最大化)<br>
[paper](https://arxiv.org/pdf/2103.04200.pdf)<br><br>

[28] Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing(用于实例感知人类语义解析的可微分多粒度人类表示学习)<br>
[paper](https://arxiv.org/pdf/2103.04570.pdf)|[code](https://github.com/tfzhou/MG-HumanParsing)<br><br>

[27] Self-supervised Geometric Perception(自我监督的几何感知)<br>
[paper](https://arxiv.org/abs/2103.03114)<br><br>

[26] Discovering Hidden Physics Behind Transport Dynamics(在运输动力学背后发现隐藏的物理)<br>
[paper](https://arxiv.org/pdf/2011.12222v1.pdf)<br><br>

[25] Learning Continuous Image Representation with Local Implicit Image Function(通过局部隐含图像功能学习连续图像表示)<br>
[paepr](https://arxiv.org/abs/2012.09161)|[code](https://github.com/yinboc/liif)|[video](https://youtu.be/6f2roieSY_8)|[project](https://yinboc.github.io/liif/)<br><br>

[24] UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)|[code](https://github.com/dddzg/up-detr)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>

[23] Self-supervised Geometric Perception(自我监督的几何知觉)<br>
[paper](https://arxiv.org/abs/2103.03114)<br><br>

[22] DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on  Cardiac Tagging Magnetic Resonance Images(一种心脏标记磁共振图像运动跟踪的无监督深度学习方法)<br>
[paper](https://arxiv.org/abs/2103.02772)<br><br>

[21] Modeling Multi-Label Action Dependencies for Temporal Action Localization(为时间动作本地化建模多标签动作相关性)<br>
[paper](https://arxiv.org/pdf/2103.03027.pdf)<br><br>

[20] HPS: localizing and tracking people in large 3D scenes from wearable sensors(通过可穿戴式传感器对大型3D场景中的人进行定位和跟踪)<br><br>

[19] Real-Time High Resolution Background Matting(实时高分辨率背景抠像)<br>
[paper](https://arxiv.org/abs/2012.07810)|[code](https://github.com/PeterL1n/BackgroundMattingV2)|[project](https://grail.cs.washington.edu/projects/background-matting-v2/)|[video](https://youtu.be/oMfPTeYDF9g)<br><br>

[18] Exploring Data-Efficient 3D Scene Understanding with Contrastive Scene Contexts(探索具有对比场景上下文的数据高效3D场景理解)<br>
[paper](http://arxiv.org/abs/2012.09165)|[project](http://sekunde.github.io/project_efficient)|[video](http://youtu.be/E70xToZLgs4)<br><br>

[17] Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments(在动态室内环境中，通过空间划分的鲁棒神经路由可实现摄像机的重新定位)<br>
[paper](https://arxiv.org/abs/2012.04746)|[project](https://ai.stanford.edu/~hewang/)<br><br>

[16] MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization(通过3D扫描同步进行多主体分割和运动估计)<br>
[paper](https://arxiv.org/pdf/2101.06605.pdf)|[code](https://github.com/huangjh-pub/multibody-sync)<br><br>

[15] Categorical Depth Distribution Network for Monocular 3D Object Detection(用于单目三维目标检测的分类深度分布网络)<br>
[paper](https://arxiv.org/abs/2103.01100)<br><br>

[14] PatchmatchNet: Learned Multi-View Patchmatch Stereo(学习多视图立体声)<br>
[paper](https://arxiv.org/abs/2012.01411)|[code](https://github.com/FangjinhuaWang/PatchmatchNet)

[13] Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning(通过域随机化和元学习对视觉表示进行连续调整)<br>
[paper](https://arxiv.org/abs/2012.04324)<br><br>

[12] Single-Stage Instance Shadow Detection with Bidirectional Relation Learning(具有双向关系学习的单阶段实例阴影检测)<br><br>

[11] Neural Geometric Level of Detail:Real-time Rendering with Implicit 3D Surfaces(神经几何细节水平：隐式3D曲面的实时渲染)<br>
[paper](https://arxiv.org/abs/2101.10994)|[code](https://github.com/nv-tlabs/nglod)|[project](https://nv-tlabs.github.io/nglod/)<br><br>

[9] PREDATOR: Registration of 3D Point Clouds with Low Overlap(预测器：低重叠的3D点云的配准)<br>
[paper](https://arxiv.org/pdf/2011.13005.pdf)|[code](https://github.com/ShengyuH/OverlapPredator)|[project](https://overlappredator.github.io/)<br><br>

[8] Domain Generalization via Inference-time Label-Preserving Target Projections(通过保留推理时间的目标投影进行域泛化)<br>
[paper](https://arxiv.org/abs/2103.01134)<br><br>

[7] Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction(全局一致的非刚性重建的神经变形图)<br>
[paper](https://arxiv.org/abs/2012.01451)|[project](https://aljazbozic.github.io/neural_deformation_graphs/)|[video](https://youtu.be/vyq36eFkdWo)<br><br>

[6] Fine-grained Angular Contrastive Learning with Coarse Labels(粗标签的细粒度角度对比学习)<br>
[paper](https://arxiv.org/abs/2012.03515)<br><br>

[5] Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling(通过稀疏采样进行视频和语言学习)<br>
[paper](https://arxiv.org/pdf/2102.06183.pdf)|[code](https://github.com/jayleicn/ClipBERT)<br><br>

[4] Cross-View Regularization for Domain Adaptive Panoptic Segmentation(用于域自适应全景分割的跨视图正则化)<br>
[paper](https://arxiv.org/abs/2103.02584)<br><br>

[3] Image-to-image Translation via Hierarchical Style Disentanglement(通过分层样式分解实现图像到图像的翻译)<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

[2] Towards Open World Object Detection(开放世界中的目标检测)<br>
[paper](https://arxiv.org/abs/2103.02603)|[code](https://github.com/JosephKJ/OWOD)<br><br>

[1] End-to-End Video Instance Segmentation with Transformers(使用Transformer的端到端视频实例分割) <br>
[paper](https://arxiv.org/abs/2011.14503)<br><br>

<br>

<a name="3"/> 

## 3. To do list

* CVPR2021论文解读
* CVPR2021论文分享
